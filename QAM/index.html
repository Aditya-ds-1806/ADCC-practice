<!DOCTYPE html>
<html lang="en">

<head>
    <meta charset="UTF-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <link href="https://cdn.jsdelivr.net/npm/bootstrap@5.1.3/dist/css/bootstrap.min.css" rel="stylesheet"
        integrity="sha384-1BmE4kWBq78iYhFldvKuhfTAU6auU8tT94WrHftjDbrCEXSU1oBoqyl2QvZ6jIW3" crossorigin="anonymous">
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.3.1/styles/default.min.css">
    <link rel="stylesheet" href="../index.css">
    <title>Quadrature Amplitude Modulation(QAM)</title>
</head>

<body class="container">
    <header class="text-center my-5 py-3">
        <h1 class="display-4">Design of QAM Receivers and SER Analysis</h1>
        <h1 class="text-secondary">Experiment - 5</h1>
    </header>

    <main>
        <section class="mb-5">
            <h2>1 Aim</h2>
            <p>To design a discrete time QAM communication receiver, and analyze the SER performance.</p>
        </section>
        <section class="mb-5">
            <h2>2 Theory</h2>
            <div class="text-center">
                <figure class="figure">
                    <img src="./images/constellation.png" class="figure-img img-fluid rounded"
                        alt="constellation for BPSK">
                    <figcaption class="figure-caption text-center">Fig.1 Constellation Map</figcaption>
                </figure>
            </div>
            <h3>2.1 ML Rule</h3>
            Since every symbol is equally likely, the ML rule is based on the shortest euclidean distance:
            $$ arg\:min\:||y-s_{i}||^2,\:i=0,1,2\dots,7 $$
            <h3>2.2 SER</h3>
            Let \(d\) be the distance between the points and \(E\) be the error bit. Let \(s_{i}\)
            be the \(i^{th}\) symbol and since all symbols are equally likely:
            $$ P(E=1) = \sum_{i=1}^7 P(s_{i})P(E \mid s_{i}) = \frac{1}{8}\sum_{i=1}^7 P(E \mid s_{i})\tag{1} $$
            Owing to the symmetry of the constellation, we can write:
            $$ P(E \mid s_{0}) = P(E \mid s_{1}) = P(E \mid s_{6}) = P(E \mid s_{7}) $$
            $$ P(E \mid s_{2}) = P(E \mid s_{3}) = P(E \mid s_{4}) = P(E \mid s_{5})\tag{2} $$
            Thus, \((1)\) reduces to:
            $$ P(E=1) = \frac{P(E \mid s_{1}) + P(E \mid s_{3})}{2}\tag{3} $$
            Let \(S_{k} = [S_{1k}, S_{2k}]\) represent the symbol transmitted and \(N_{k} = [N_{1k}, N_{2k}]\) be
            the noise introudced by the AWGN channel such that \(Y_{k} = [Y_{1k}, Y_{2k}] = N_{k} + S_{k}\). Then,
            $$ P(E \mid s_{1}) = P(\{Y_{1k} > -d\} \cap \{P(Y_{2k} > 0)\}) $$
            $$ = 1 - P(\{Y_{1k} < -d\} \cap \{P(Y_{2k} < 0)\})$$ $$=1 - P(Y_{1k} < -d)P(Y_{2k} < 0) $$ $$=1 - P(S_{1k} +
                N_{1k} < -d)P(S_{2k} + N_{2k} < 0) $$ $$=1 - P(N_{1k} - 3d/2 < -d)P(N_{2k} - d/2 < 0) $$ $$=1 - P(N_{1k}
                < d/2)P(N_{2k} < d/2) $$ $$=1 - (1 - P(N_{1k}> d/2))^2 $$
                $$ = 1 - \Bigg(1 - P\Bigg(\frac{N_{1k}}{\sigma} > \frac{d}{2\sigma}\Bigg)\Bigg)^2 $$
                $$ = 1 - \Bigg(1 - Q\Bigg(\frac{d}{2\sigma}\Bigg)\Bigg)^2 $$
                $$ = 2Q\Big(\frac{d}{2\sigma}\Big) - Q^2\Big(\frac{d}{2\sigma}\Big)\tag{4} $$
                Similarly,
                $$ P(E \mid s_{3}) = P(\{Y_{1k} < -d, Y_{1k}> 0\} \cap \{P(Y_{2k} > 0)\}) $$
                    $$ = 1 - P(\{-d < Y_{1k} < 0\} \cap \{P(Y_{2k} < 0)\})$$ $$=1 - P(-d < Y_{1k} < 0)P(Y_{2k} < 0) $$
                        $$=1 - P(-d < S_{1k} + N_{1k} < 0)P(S_{2k} + N_{2k} < 0) $$ $$=1 - P(-d < N_{1k} - d/2 <
                        0)P(N_{2k} - d/2 < 0) $$ $$=1 - P(-d/2 < N_{1k} < d/2)P(N_{2k} < d/2) $$ $$=1 -
                        P\Big(-\frac{d}{2\sigma} < N_{1k} < \frac{d}{2\sigma}\Big)P\Big(\frac{N_{2k}}{\sigma} <
                        \frac{d}{2\sigma}\Big) $$ $$=1 - P\Big(-\frac{d}{2\sigma} < N_{1k} <
                        \frac{d}{2\sigma}\Big)P\Big(\frac{N_{2k}}{\sigma} < \frac{d}{2\sigma}\Big) $$ $$=1 - \Bigg(1 -
                        P\Big(\frac{d}{2\sigma}> N_{1k} > -\frac{d}{2\sigma}\Big)\Bigg)\Bigg(1 -
                        P\Big(\frac{N_{2k}}{\sigma} > \frac{d}{2\sigma}\Big)\Bigg) $$
                        $$ = 1 - \Bigg(1 - 2Q\Big(\frac{d}{2\sigma}\Big)\Bigg)\Bigg(1 -
                        Q\Big(\frac{d}{2\sigma}\Big)\Bigg) $$
                        $$ = 3Q\Big(\frac{d}{2\sigma}\Big) - 2Q^2\Big(\frac{d}{2\sigma}\Big)\tag{5} $$
                        Substituting \((4)\) and \((5)\) in \((3)\):
                        $$ \boxed{P(E=1) = 2.5Q\Big(\frac{d}{2\sigma}\Big) - 1.5Q^2\Big(\frac{d}{2\sigma}\Big)}\tag{6}
                        $$
                        The average symbol energy can be found from the constellation map as:
                        $$ E_{s} = \sum_{k}P(s_{k})|s_{k}|^2 = \frac{4(\frac{d^2}{4} + \frac{d^2}{4}) + 4(\frac{9d^2}{4}
                        + \frac{d^2}{4})}{8} $$
                        $$ E_{s} = \frac{3d^2}{2}\tag{7} $$
                        Substituting (7) in (6):
                        $$ \boxed{P_{e} = P(E=1) = 2.5Q\Bigg(\sqrt{\frac{E_{s}}{3N_{0}}}\Bigg) -
                        1.5Q^2\Bigg(\sqrt{\frac{E_{s}}{3N_{0}}}\Bigg)}\tag{8} $$
        </section>
        <section class="mb-5">
            <h2>3 Design</h2>
            <code class="fs-6">
                <pre>
Input: NO_OF_BITS, EB_N0_DB, Bk, d=1
Output: SER

constellation = [(±0.5 ± i, ±0.5)], i = 0, 1

map(symbol) = constellation[bin2dec(symbol)]
ML(Y) = argmin euclidean_distance(Y, constellation)

Sk = map(Bk.group(3))

for EB_N0 in EB_N0_DB
    Nk = AWGN(EB_N0, 2D)
    Yk = Sk + Nk
    sHat = dec2bin(ML(Yk))
    unchangedSymbols = count(sHat === Sk)
    SER = 1 - (unchangedSymbols/NO_OF_BITS)

plot(SER, SER_THEORETICAL)
                </pre>
            </code>
        </section>
        <section id="code" class="mb-5">
            <h2>4 JavaScript Code</h2>
        </section>
        <section class="mb-5">
            <h2>5 Results and Inferences</h2>
            <div id="plot"></div>
            <div class="d-flex justify-content-center my-4">
                <div>
                    <input type="number" class="form-control" id="D" placeholder="Enter D" min="2">
                </div>
                <button class="btn btn-primary mx-5" id="simulate">
                    Simulate
                    <span class="spinner-border spinner-border-sm d-none"></span>
                </button>
                <button class="btn btn-primary mx-5" id="simulation" disabled>Save Simulation Data</button>
                <button class="btn btn-primary mx-5" id="theory" disabled>Save Theoretical Data</button>
            </div>
            <div class="row">
                <div class="col-sm-6">
                    <figure class="figure">
                        <img src="./D=0.1/images/10^5.svg" class="figure-img img-fluid rounded">
                        <figcaption class="figure-caption text-center">Fig.2 Simulation result for \(d=0.1\) with \(3\times10^5\) bits
                        </figcaption>
                    </figure>
                </div>
                <div class="col-sm-6">
                    <figure class="figure">
                        <img src="./D=0.25/images/10^5.svg" class="figure-img img-fluid rounded">
                        <figcaption class="figure-caption text-center">Fig.3 Simulation result for \(d=0.25\) with \(3\times10^5\) bits
                        </figcaption>
                    </figure>
                </div>
                <div class="col-sm-6">
                    <figure class="figure">
                        <img src="./D=0.5/images/10^5.svg" class="figure-img img-fluid rounded">
                        <figcaption class="figure-caption text-center">Fig.4 Simulation result for \(d=0.5\) with \(3\times10^5\) bits
                        </figcaption>
                    </figure>
                </div>
                <div class="col-sm-6">
                    <figure class="figure">
                        <img src="./D=1/images/10^5.svg" class="figure-img img-fluid rounded">
                        <figcaption class="figure-caption text-center">Fig.5 Simulation result for \(d=1\) with \(3\times10^5\) bits
                        </figcaption>
                    </figure>
                </div>
            </div>
            <figure class="figure">
                <img src="./images/comparison.png" class="figure-img img-fluid rounded">
                <figcaption class="figure-caption text-center">Fig.6 Comparison of simulation results for \(d=0.1,0.25,0.5,1\)
                </figcaption>
            </figure>
            <p>
                From the above figures, it can be seen that for a given \(d\), the simulated \(P_{e}\) and theoretical \(P_{e}\)
                match better with increase in the number of bits. This is because, to get confidence in the simulated results,
                there must be sufficient number of bit errors. For example, to get a bit error rate of \(10^{-5}\), one needs to
                send at least \(10^6\) bits. Also, it can be seen that the \(P_{e}\) reduces graudally with increase in
                \(\frac{E_{s}}{N_{0}}\), the SNR per symbol. This is due to the fact that as the SNR per symbol increases,
                the signal becomes less affected by the presence of noise, thus reducing errors in ML detection.
                Finally, another important thing to be noted is that the simulated curve is not only affected by the symbol errors,
                but is also affected by floating point errors.
            </p>
            <p>
                From figure \(6\), we can see that the waterfall curve tends to flatten with decrease in \(d\). This is because,
                with decrease in \(d\) the decision region becomes smaller and hence vastly increases the chances of symbol error.
                This also explains the fact that for larger \(d\), the curves start from a lower SER closer to 0 and as
                \(D\to\infty, SER\to0\).
            </p>
        </section>
    </main>

    <script src="https://cdnjs.cloudflare.com/ajax/libs/jstat/1.9.5/jstat.min.js"
        integrity="sha512-MGT8BGoc8L3124PwHEGTC+M8Hu9oIbZOg8ENcd92sQKKidWKOOOZ6bqQemqYAX0yXJUnovOkF4Hx9gc/5lVxPw=="
        crossorigin="anonymous" referrerpolicy="no-referrer"></script>
    <script src="https://cdn.plot.ly/plotly-2.4.2.min.js"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.3.1/highlight.min.js"></script>
    <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    <script type="module" src="index.js"></script>
</body>

</html>
