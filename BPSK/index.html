<!DOCTYPE html>
<html lang="en">

<head>
    <meta charset="UTF-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <link href="https://cdn.jsdelivr.net/npm/bootstrap@5.1.3/dist/css/bootstrap.min.css" rel="stylesheet"
        integrity="sha384-1BmE4kWBq78iYhFldvKuhfTAU6auU8tT94WrHftjDbrCEXSU1oBoqyl2QvZ6jIW3" crossorigin="anonymous">
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.3.1/styles/default.min.css">
    <link rel="stylesheet" href="../index.css">
    <title>Binary Phase Shift Keying(BPSK)</title>
</head>

<body class="container">
    <header class="text-center my-5 py-3">
        <h1 class="display-4">Design of BPSK Receivers and BER Analysis</h1>
        <h1 class="text-secondary">Experiment - 1</h1>
    </header>

    <main>
        <section class="mb-5">
            <h2>1 Aim</h2>
            <p>To design a discrete time BPSK communication receiver, and analyze the BER performance.</p>
        </section>
        <section class="mb-5">
            <h2>2 Theory</h2>
            <figure class="figure">
                <img src="./images/constellation.png" class="figure-img img-fluid rounded" alt="constellation for BPSK">
                <figcaption class="figure-caption text-center">Fig.1 Constellation Map</figcaption>
            </figure>
            <h3>2.1 ML Rule</h3>
            Let \(Y\) be the output at the receiver and \(X\) be the message at the transmitter. Let \(N\) be the noise
            introduced by the AWGN channel. Let \(E_{b}\) be the bit energy. Then, for the
            \(k^{th}\) bit:
            $$ Y_{k} = X_{k} + N_{k} $$
            Consider:
            $$ P(Y_{k} = y \mid X_{k} = \sqrt{E_{b}}) $$
            $$ = \lim_{\epsilon \to 0} P(Y_{k} \in (y-\epsilon, y+\epsilon) \mid X_{k}=\sqrt{E_{b}}) $$
            $$ = \lim_{\epsilon \to 0} P(X_{k} + N_{k} \in (y-\epsilon, y+\epsilon) \mid X_{k}=\sqrt{E_{b}}) $$
            $$ = \lim_{\epsilon \to 0} P(N_{k} \in (y-\epsilon-\sqrt{E_{b}}, y+\epsilon-\sqrt{E_{b}}) \mid
            X_{k}=\sqrt{E_{b}}) $$
            $$ = \lim_{\epsilon \to 0} 2\epsilon f_{Y_{k}}(y-\sqrt{E_{b}}) $$
            $$ \boxed{P(Y_{k} = y \mid X_{k} = \sqrt{E_{b}}) = \lim_{\epsilon \to 0} 2\epsilon
            f_{Y_{k}}(y-\sqrt{E_{b}})}\tag{1}
            $$
            Similarly:
            $$ \boxed{P(Y_{k} = y \mid X_{k} = -\sqrt{E_{b}}) = \lim_{\epsilon \to 0} 2\epsilon
            f_{Y_{k}}(y+\sqrt{E_{b}})}\tag{2} $$
            Consider the ratio of \((1)\) and \((2)\):
            $$ \frac{P(Y_{k} = y \mid X_{k} = \sqrt{E_{b}})}{P(Y_{k} = y \mid X_{k} = -\sqrt{E_{b}})} = \lim_{\epsilon
            \to
            0}\frac{2\epsilon f_{Y_{k}}(y-\sqrt{E_{b}})}{2\epsilon f_{Y_{k}}(y+\sqrt{E_{b}})} $$
            $$ = \frac{f_{Y_{k}}(y-\sqrt{E_{b}})}{f_{Y_{k}}(y+\sqrt{E_{b}})} $$
            $$ =
            \frac{\frac{1}{\sigma\sqrt{2}\pi}e^{-\frac{(y-\sqrt{E_{b}})^2}{2\sigma^2}}}{\frac{1}{\sigma\sqrt{2}\pi}e^{-\frac{(y+\sqrt{E_{b}})^2}{2\sigma^2}}}
            $$
            $$ = e^{\frac{(y+\sqrt{E_{b}})^2 - (y-\sqrt{E_{b}})^2}{2\sigma^2}} $$
            $$ = e^{\frac{4y\sqrt{E_{b}}}{2\sigma^2}} $$
            $$ = e^{\frac{2y\sqrt{E_{b}}}{\sigma^2}} $$
            $$ \boxed{\frac{P(Y_{k} = y \mid X_{k} = \sqrt{E_{b}})}{P(Y_{k} = y \mid X_{k} = -\sqrt{E_{b}})} =
            e^{\frac{2y\sqrt{E_{b}}}{\sigma^2}}}\tag{3} $$
            Let \(B_{k} \in X \) be the transmitted bit and \(\hat{B} \in Y\) be the the output at the receiver
            corresponding to \(B_{k}\). Then the ML can be written as:
            $$ \hat{B} =
            \begin{cases}
            1, & \frac{P(Y_{k}=y \mid B_{k}=1)}{P(Y_{k}=y \mid B_{k}=0)} > 1\\
            0, & \frac{P(Y_{k}=y \mid B_{k}=1)}{P(Y_{k}=y \mid B_{k}=0)} < 1 \end{cases} $$ $$ \hat{B}=\begin{cases} 1,
                & \ln\Big({\frac{P(Y_{k}=y \mid B_{k}=1)}{P(Y_{k}=y \mid B_{k}=0)}}\Big)> 0\\
                0, & \ln\Big({\frac{P(Y_{k}=y \mid B_{k}=1)}{P(Y_{k}=y \mid B_{k}=0)}}\Big) < 0 \end{cases} $$ Fromt he
                    constellation diagram, we can write: $$ \hat{B}=\begin{cases} 1, & \ln\Big({\frac{P(Y_{k}=y \mid
                    X_{k}=-\sqrt{E_{b}})}{P(Y_{k}=y \mid X_{k}=\sqrt{E_{b}})}}\Big)> 0\\
                    0, & \ln\Big({\frac{P(Y_{k}=y \mid X_{k}=-\sqrt{E_{b}})}{P(Y_{k}=y \mid X_{k}=\sqrt{E_{b}})}}\Big) <
                        0 \end{cases}\tag{4} $$ Substituting \((3)\) in \((4)\): $$ \hat{B}=\begin{cases} 1, &
                        \frac{2y\sqrt{E_{b}}}{\sigma^2} < 0\\ 0, & \frac{2y\sqrt{E_{b}}}{\sigma^2}> 0
                        \end{cases} $$
                        $$ \hat{B} =
                        \begin{cases}
                        1, & y < 0\\ 0, & y> 0
                            \end{cases} $$
                            <h3>2.2 BER</h3>
                            Let \(E\) be the error bit. Then,
                            $$ P(E=1) = P(E=1, B=1) + P(E=1, B=0) $$
                            $$ P(E=1) = P(E=1 \mid B=1)P(B=1) + P(E=1 \mid B=0)P(B=0)\tag{5} $$
                            $$ P(E=1 \mid B=1) = P(\hat{B}=0 \mid B=1) $$
                            $$ = P(Y>0 \mid B=1) $$
                            $$ = P(N - \sqrt{E_{b}} > 0 \mid B=1) $$
                            $$ = P(N > \sqrt{E_{b}} \mid B=1) $$
                            $$ = P(N > \sqrt{E_{b}}) $$
                            $$ = P\Big(\frac{N}{\sigma} > \sqrt{\frac{E_{b}}{\sigma^2}}\Big) $$
                            $$ = \int_{\sqrt{\frac{E_{b}}{\sigma^2}}}^{\infty}\frac{1}{\sqrt{2\pi}}e^{-\frac{x^2}{2}}dx
                            $$
                            $$ = Q\Bigg(\sqrt{\frac{E_{b}}{\sigma^2}}\Bigg) $$
                            $$ = Q\Bigg(\sqrt{\frac{2E_{b}}{N_{0}}}\Bigg)\tag{6} $$
                            Similarly,
                            $$ P(E=1 \mid B=0) = Q\Bigg(\sqrt{\frac{2E_{b}}{N_{0}}}\Bigg)\tag{7} $$
                            Substituting, \((6)\) and \((7)\) in \((5)\),
                            $$ \boxed{\therefore P_{e} = P(E=1) = Q\Bigg(\sqrt{\frac{2E_{b}}{N_{0}}}\Bigg)} $$
        </section>
        <section class="mb-5">
            <h2>3 Design</h2>
            <code class="fs-6">
                <pre>
Input: NO_OF_BITS, EB_N0_DB, Bk
Output: BER

Xk = Bk(0 --> 1, 1 --> -1)
ML(point) = (0 if point > 0; 1 if point < 0)

for EB_N0 in EB_N0_DB
    Nk = AWGN(EB_N0, 1D)
    Yk = Xk + Nk
    bHat = ML(Yk)
    unchangedBits = count(bHat === Bk)
    BER = 1 - (unchangedBits/NO_OF_BITS)

plot(BER, BER_THEORETICAL)
                </pre>
            </code>
        </section>
        <section id="code" class="mb-5">
            <h2>4 JavaScript Code</h2>
        </section>
        <section class="mb-5">
            <h2>5 Results and Inference</h2>
            <div id="plot"></div>
            <div class="d-flex justify-content-center mt-4">
                <button class="btn btn-primary mx-5" id="simulate">
                    Simulate
                    <span class="spinner-border spinner-border-sm d-none"></span>
                </button>
                <button class="btn btn-primary mx-5" id="simulation" disabled>Save Simulation Data</button>
                <button class="btn btn-primary mx-5" id="theory" disabled>Save Theoretical Data</button>
            </div>
            <div class="row">
                <div class="col-sm-6">
                    <figure class="figure">
                        <img src="./images/10^3.svg" class="figure-img img-fluid rounded">
                        <figcaption class="figure-caption text-center">Fig.2 Simulation result with \(10^3\) bits</figcaption>
                    </figure>
                </div>
                <div class="col-sm-6">
                    <figure class="figure">
                        <img src="./images/10^4.svg" class="figure-img img-fluid rounded">
                        <figcaption class="figure-caption text-center">Fig.3 Simulation result with \(10^4\) bits</figcaption>
                    </figure>
                </div>
                <div class="col-sm-6">
                    <figure class="figure">
                        <img src="./images/10^5.svg" class="figure-img img-fluid rounded">
                        <figcaption class="figure-caption text-center">Fig.4 Simulation result with \(10^5\) bits</figcaption>
                    </figure>
                </div>
                <div class="col-sm-6">
                    <figure class="figure">
                        <img src="./images/10^6.svg" class="figure-img img-fluid rounded">
                        <figcaption class="figure-caption text-center">Fig.5 Simulation result with \(10^6\) bits</figcaption>
                    </figure>
                </div>
            </div>
            <p>
                From the above figures, it can be seen that simulated \(P_{e}\) and theoretical \(P_{e}\) match better with
                increase in the number of bits. This is because, to get confidence in the simulated results, there must be 
                sufficient number of bit errors. For example in figure \((5)\), to get a bit error rate of \(10^{-5}\), one needs to send at 
                least \(10^6\) bits. Similar conclusions can be drawn from the other figures shown above. Also, it can be
                seen that the \(P_{e}\) reduces graudally with increase in \(\frac{E_{b}}{N_{0}}\), the SNR per bit. This 
                is due to the fact that as the SNR per bit increases, the signal becomes less affected by the presence of 
                noise, thus reducing errors in ML detection. Finally, another important thing to be noted is that the simulated
                curve is not only affected by the symbol errors, but is also affected by floating point errors.
            </p>
        </section>
    </main>

    <script src="https://cdnjs.cloudflare.com/ajax/libs/jstat/1.9.5/jstat.min.js"
        integrity="sha512-MGT8BGoc8L3124PwHEGTC+M8Hu9oIbZOg8ENcd92sQKKidWKOOOZ6bqQemqYAX0yXJUnovOkF4Hx9gc/5lVxPw=="
        crossorigin="anonymous" referrerpolicy="no-referrer"></script>
    <script src="https://cdn.plot.ly/plotly-2.4.2.min.js"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.3.1/highlight.min.js"></script>
    <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    <script type="module" src="index.js"></script>
</body>

</html>
